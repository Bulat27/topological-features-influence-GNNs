{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSCX7mmiScDD"
      },
      "source": [
        "# Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oISl_AJMCYUl"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fSVCVnakyty"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "    --extra-index-url=https://pypi.nvidia.com \\\n",
        "    cudf-cu12==23.12.* dask-cudf-cu12==23.12.* cuml-cu12==23.12.* \\\n",
        "    cugraph-cu12==23.12.* cuspatial-cu12==23.12.* cuproj-cu12==23.12.* \\\n",
        "    cuxfilter-cu12==23.12.* cucim-cu12==23.12.* pylibraft-cu12==23.12.* \\\n",
        "    raft-dask-cu12==23.12.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YLJhFKwkq1V"
      },
      "outputs": [],
      "source": [
        "# GPU-accelerated models (for ensemble)\n",
        "from cuml import svm\n",
        "from cuml import LogisticRegression\n",
        "from cuml.common import logger\n",
        "\n",
        "logger.set_level(logger.level_warn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx3P0_wSie3S"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import experiments\n",
        "import features\n",
        "import utilities\n",
        "import gat\n",
        "import gcn\n",
        "import node2vec\n",
        "import ensemble\n",
        "import torch\n",
        "import model\n",
        "import pickle as pk\n",
        "import os\n",
        "from google.colab import drive\n",
        "import time\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRskOYKY6g0E"
      },
      "source": [
        "# Experiment 1: basic GAT + combinations of structural and positional features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G, data = datasets.load_data('ogbn-arxiv')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "HdfB-FYgJg7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikf7lSi0Slgw"
      },
      "outputs": [],
      "source": [
        "# Global model variables\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATBase(data, 8, 8)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFqbzdAvUjQN"
      },
      "outputs": [],
      "source": [
        "# Global features\n",
        "\n",
        "original_features = data.x.to(device)\n",
        "structural_features = features.structural_features(G, ['cc', 'bc', 'dc', 'ec', 'pr', 'cn', 'lc', 'nd', 'kc']).to(device)\n",
        "positional_features = features.positional_features(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtcWZzU8S05A"
      },
      "outputs": [],
      "source": [
        "# Experiments helper functions. Keep in mind: They use the global variables!\n",
        "\n",
        "def gat_base_factory(data, hidden_channels, heads):\n",
        "  return gat.GATBase(data, hidden_channels, heads)\n",
        "\n",
        "def gat_pre_factory(data, hidden_channels, heads, mlp_hidden_channels):\n",
        "  return gat.GATPre(data, hidden_channels, heads, mlp_hidden_channels)\n",
        "\n",
        "def gcn_base_factory(data, hidden_channels):\n",
        "  return gcn.GCNBase(data, hidden_channels)\n",
        "\n",
        "def gcn_pre_factory(data, hidden_channels, mlp_hidden_channels):\n",
        "  return gcn.GCNPre(data, hidden_channels, mlp_hidden_channels)\n",
        "\n",
        "def run_feature_combinations(file_name, model_factory, global_model_params, normalization=lambda x: x):\n",
        "    features_combinations = [\n",
        "      original_features,\n",
        "      structural_features,\n",
        "      positional_features,\n",
        "      utilities.concatenate(original_features,structural_features),\n",
        "      utilities.concatenate(original_features,positional_features),\n",
        "      utilities.concatenate(structural_features,positional_features),\n",
        "      utilities.concatenate(original_features,structural_features,positional_features)]\n",
        "\n",
        "    file_names = [\n",
        "      'original',\n",
        "      'structural',\n",
        "      'positional',\n",
        "      'original-structural',\n",
        "      'original-positional',\n",
        "      'structural-positional',\n",
        "      'original-structural-positional']\n",
        "\n",
        "    basic_models = dict()\n",
        "    for curr_features, curr_file_name in zip(features_combinations, file_names):\n",
        "        data.x = curr_features\n",
        "        data.x = normalization(data.x)\n",
        "\n",
        "        if data.name=='Cora' and (curr_file_name=='original' or curr_file_name=='original-structural' or curr_file_name=='original-positional' or curr_file_name=='original-structural-positional'):\n",
        "          split = curr_features.split([orig_num_feat,curr_features.size()[1]-orig_num_feat],dim=-1)\n",
        "          orig_feats = split[0]\n",
        "          other_feats = split[1]\n",
        "          other_feats_norm = normalization(other_feats)\n",
        "          data.x = utilities.concatenate(orig_feats,other_feats_norm)\n",
        "\n",
        "        model = model_factory(data, *global_model_params)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "        results = dict()\n",
        "        results['avg_acc'], results['test_accs'], results['train_losses'], results['train_accs'], results['val_losses'], results['val_accs'], results['run_times'],results['best_epoch'] = experiments.run_experiments(model, data, n_runs, n_epochs, optimizer, criterion, device) # These should be \"global variables\"\n",
        "        results['model'] = model\n",
        "\n",
        "        basic_models[curr_file_name] = results\n",
        "\n",
        "    utilities.save_results(basic_models, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9xCDCAj6186"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-base-concatenation-without-norm', gat_base_factory, global_model_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR-wYzZUWv7p"
      },
      "outputs": [],
      "source": [
        "gat_base_concatenation_without_norm = utilities.load_results('gat-base-concatenation-without-norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz1YyqSDhtak"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-base-concatenation-without-norm.pkl')\n",
        "utilities.save_results(gat_base_concatenation_without_norm, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c-R2zRoiTym"
      },
      "outputs": [],
      "source": [
        "print(gat_base_concatenation_without_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lbQ-_ktl7oH"
      },
      "source": [
        "### Adding Min-Max Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C_C8xekmFVJ"
      },
      "outputs": [],
      "source": [
        "# Global model variables\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATBase(data, 8, 8)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZcoHjqIkers"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-base-concatenation-minmax-norm', gat_base_factory, global_model_params, normalization=utilities.MinMaxNormalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtXRlsiZkua1"
      },
      "outputs": [],
      "source": [
        "gat_base_concatenation_minmax_norm = utilities.load_results('gat-base-concatenation-minmax-norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gMBaJFAiJju"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-base-concatenation-minmax-norm.pkl')\n",
        "utilities.save_results(gat_base_concatenation_minmax_norm, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ2F_1qalK7_"
      },
      "outputs": [],
      "source": [
        "print(gat_base_concatenation_minmax_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIVhsMffmBKr"
      },
      "source": [
        "### Adding Z-Score Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i7CIU7CnE3p"
      },
      "outputs": [],
      "source": [
        "# Global model variables\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATBase(data, 8, 8)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5T_vWB5nYOC"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-base-concatenation-standard-norm', gat_base_factory, global_model_params, normalization=utilities.StandardNormalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ0B4JE-nIcx"
      },
      "outputs": [],
      "source": [
        "gat_base_concatenation_standard_norm = utilities.load_results('gat-base-concatenation-standard-norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPe9UfGoiRJ9"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-base-concatenation-standard-norm.pkl')\n",
        "utilities.save_results(gat_base_concatenation_standard_norm, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfqf4Wp5nIvd"
      },
      "outputs": [],
      "source": [
        "print(gat_base_concatenation_standard_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3RtOYGflTCZ"
      },
      "source": [
        "## Experiment 2: GAT with MLP preprocessing on all the feature combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBqQE9FgX0ZQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATPre(data, 8, 8, 128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLpPTiswrGtm"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-pre-concatenation-without-norm', gat_pre_factory, global_model_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywynAXC8sEPA"
      },
      "outputs": [],
      "source": [
        "gat_pre_concatenation_without_norm = utilities.load_results('gat-pre-concatenation-without-norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2NnQkMviZ-8"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-pre-concatenation-without-norm.pkl')\n",
        "utilities.save_results(gat_pre_concatenation_without_norm, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV6lspfOsjaW"
      },
      "outputs": [],
      "source": [
        "print(gat_pre_concatenation_without_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL1zrE-MumqO"
      },
      "source": [
        "# 160 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21Nr5Herul_h"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATPre(data, 8, 8, 160)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8, 160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEXFbxuuuuzS"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-pre-concatenation-without-norm-160', gat_pre_factory, global_model_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf8k6yq0uzTh"
      },
      "outputs": [],
      "source": [
        "gat_pre_concatenation_without_norm_160 = utilities.load_results('gat-pre-concatenation-without-norm-160')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpofA7HgigTo"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-pre-concatenation-without-norm-160.pkl')\n",
        "utilities.save_results(gat_pre_concatenation_without_norm_160, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxlasUwTu6ED"
      },
      "outputs": [],
      "source": [
        "print(gat_pre_concatenation_without_norm_160)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjwS_ykIsyf6"
      },
      "source": [
        "# Adding Z-Score Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYqefqF-syKd"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATPre(data, 8, 8, 128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPRAa7krtFCH"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-pre-concatenation-standard-norm', gat_pre_factory, global_model_params, utilities.StandardNormalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfWGfm_0thNI"
      },
      "outputs": [],
      "source": [
        "gat_pre_concatenation_standard_norm = utilities.load_results('gat-pre-concatenation-standard-norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-kEpSUEiqhG"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-pre-concatenation-standard-norm.pkl')\n",
        "utilities.save_results(gat_pre_concatenation_standard_norm, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKf7LvLUtY6K"
      },
      "outputs": [],
      "source": [
        "print(gat_pre_concatenation_standard_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zR3hkXEvFQl"
      },
      "source": [
        "# 160 Standard norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVOPCRIkvOrO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = gat.GATPre(data, 8, 8, 160)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 10\n",
        "global_model_params = [8, 8, 160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5cGOqFCvRfV"
      },
      "outputs": [],
      "source": [
        "run_feature_combinations('gat-pre-concatenation-standard-norm-160', gat_pre_factory, global_model_params, utilities.StandardNormalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4wW3S5UvTAB"
      },
      "outputs": [],
      "source": [
        "gat_pre_concatenation_standard_norm_160 = utilities.load_results('gat-pre-concatenation-standard-norm-160')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg1o-mTHixel"
      },
      "outputs": [],
      "source": [
        "full_path = os.path.join(\"/content/drive/My Drive/\", 'gat-pre-concatenation-standard-norm-160.pkl')\n",
        "utilities.save_results(gat_pre_concatenation_standard_norm_160, full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08nSid4-vUWz"
      },
      "outputs": [],
      "source": [
        "print(gat_pre_concatenation_standard_norm_160)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yWiPkNElv1c"
      },
      "source": [
        "## GAT ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZodm9BmltbM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import numpy\n",
        "import gc\n",
        "from model import model_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWgycvDO62Su"
      },
      "outputs": [],
      "source": [
        "data_clone = data.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiNsg9vOLV6-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_original = gat.GATBase(data, 8, 8)\n",
        "model_positional = gat.GATBase(data, 8, 8)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "n_epochs = 200\n",
        "n_runs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxltiPngN8j5"
      },
      "outputs": [],
      "source": [
        "identity_normalizer = FunctionTransformer(lambda x: x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni_GZrKBY49d"
      },
      "outputs": [],
      "source": [
        "data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXDIF_TVCo5Q"
      },
      "outputs": [],
      "source": [
        "def run_ensemble(data_orig, classifier, scaler, n_runs, file_name):\n",
        "\n",
        "  test_accs, run_times = [], []\n",
        "  for i in range(n_runs):\n",
        "    print(f\"\\n RUN: {i}\\n\")\n",
        "\n",
        "    data = data_orig.clone()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    data.val_mask, data.ensemble_val_mask = ensemble.get_val_set_split(data)\n",
        "\n",
        "    data.x = original_features\n",
        "    model_original = gat.GATBase(data, 8, 8)\n",
        "    model_original = model_original.to(device)\n",
        "    optimizer = torch.optim.Adam(model_original.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "    train_losses, train_accs, val_losses, val_accs, best_epoch = model_training(n_epochs, model_original, data, optimizer, criterion)\n",
        "\n",
        "    print(f\"\\n Model with original features: training completed\\n\")\n",
        "\n",
        "    data.x = positional_features\n",
        "    model_positional = gat.GATBase(data, 8, 8)\n",
        "    model_positional = model_positional.to(device)\n",
        "    optimizer = torch.optim.Adam(model_positional.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "    train_losses, train_accs, val_losses, val_accs, best_epoch = model_training(n_epochs, model_positional, data, optimizer, criterion)\n",
        "\n",
        "    print(f\"\\n Model with positional features: training completed\\n\")\n",
        "\n",
        "    models = [model_original, model_positional]\n",
        "    features = [original_features, positional_features]\n",
        "\n",
        "    meta_model_train = ensemble.get_meta_model_features(models, features, data.ensemble_val_mask, data.edge_index)\n",
        "    meta_model_test = ensemble.get_meta_model_features(models, features, data.test_mask, data.edge_index)\n",
        "\n",
        "    X_train = meta_model_train.cpu().numpy()\n",
        "    y_train = data.y[data.ensemble_val_mask].cpu().numpy()\n",
        "    X_test = meta_model_test.cpu().numpy()\n",
        "    y_test = data.y[data.test_mask].cpu().numpy()\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    y_pred = classifier.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    test_accs.append(accuracy)\n",
        "    run_times.append(end_time - start_time)\n",
        "\n",
        "    print(f\"\\n Ensemble: training completed\")\n",
        "    print(f\"Ensemble accuracy: {accuracy}\")\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  results = dict()\n",
        "  results['test_accs'] = test_accs\n",
        "  results['avg_acc'] = sum(test_accs) / len(test_accs)\n",
        "  results['model'] = classifier\n",
        "  results['run_time'] = run_times\n",
        "\n",
        "  utilities.save_results(results, file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62APKpLfjOtY"
      },
      "source": [
        "# SVM no normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PLxyCd4D9Z8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, svm.SVC(verbose=0), identity_normalizer, 5, 'ensemble_SVM_non_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JXrXE8TjpqI"
      },
      "outputs": [],
      "source": [
        "ensemble_svm_non_norm = utilities.load_results('ensemble_SVM_non_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMh3jCkVjzqO"
      },
      "outputs": [],
      "source": [
        "print(ensemble_svm_non_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osGlnWxujSjB"
      },
      "source": [
        "# SVM with normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PFRYTFwyiqCF"
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, svm.SVC(verbose=0), StandardScaler(), 5, 'ensemble_SVM_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Wx9cq-ol5n0"
      },
      "outputs": [],
      "source": [
        "ensemble_svm_std_norm = utilities.load_results('ensemble_SVM_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WD_0vkBImSpp"
      },
      "outputs": [],
      "source": [
        "print(ensemble_svm_std_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRNquO7bjU80"
      },
      "source": [
        "# LR no normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozzf3brljXDj"
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, LogisticRegression(max_iter=10000, multi_class=\"multinomial\",verbose=0), identity_normalizer, 5, 'ensemble_LR_no_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KpNVGXPp0LU"
      },
      "outputs": [],
      "source": [
        "ensemble_lr_non_norm = utilities.load_results('ensemble_LR_no_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQD3wygp8mM"
      },
      "outputs": [],
      "source": [
        "print(ensemble_lr_non_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF2eyl8tjXYT"
      },
      "source": [
        "# LR with normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gmb1iDpqDtP"
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, LogisticRegression(max_iter=10000, multi_class=\"multinomial\",verbose=0), StandardScaler(), 5, 'ensemble_LR_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtafGQ8DqJ1J"
      },
      "outputs": [],
      "source": [
        "ensemble_lr_std_norm = utilities.load_results('ensemble_LR_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWfNVDmhqNAw"
      },
      "outputs": [],
      "source": [
        "print(ensemble_lr_std_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwyQGR5kjdaS"
      },
      "source": [
        "# DT no normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkPj-q0DrUvT"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUuk56Ipjceo"
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, DecisionTreeClassifier(), identity_normalizer, 5, 'ensemble_DT_non_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd5jXkpqrabx"
      },
      "outputs": [],
      "source": [
        "ensemble_dt_non_norm = utilities.load_results('ensemble_DT_non_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y27tF48frd4T"
      },
      "outputs": [],
      "source": [
        "print(ensemble_dt_non_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRCy3uAgjfig"
      },
      "source": [
        "# DT with normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rZTcERtrrr4"
      },
      "outputs": [],
      "source": [
        "run_ensemble(data, DecisionTreeClassifier(), StandardScaler(), 5, 'ensemble_DT_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O83EbMNnrvRk"
      },
      "outputs": [],
      "source": [
        "ensemble_dt_std_norm = utilities.load_results('ensemble_DT_std_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZw6QhZcrzUH"
      },
      "outputs": [],
      "source": [
        "print(ensemble_dt_std_norm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}